{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Japanese-Russian Translationese: prepare features.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOLHiyj71fkGpBVe964DS5d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mjolnika/japanese-russian-translationese/blob/main/Japanese_Russian_Translationese_prepare_features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compute additional features"
      ],
      "metadata": {
        "id": "vmyye_gZu5KI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Addendum to code by Kunilovskaya & Lapshinova-Koltunski (https://github.com/kunilovskaya/translationese45)"
      ],
      "metadata": {
        "id": "kaS0oh3zvIuT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## directs"
      ],
      "metadata": {
        "id": "GOdn83s7yJSw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "regular expressions from hselingapi direct speech (https://github.com/hseling/hseling-api-direct-speech/blob/master/hseling_api_direct_speech/csv_files/speech.csv)"
      ],
      "metadata": {
        "id": "yeMGpmE3yMf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#LEFT_CONTEXT9speech9RIGHT_CONTEXT\n",
        "spdict = []\n",
        "speech = r'''(?<!:)\\n\\s*?9[—–-]{1,2}.+?[\\.\\?!]*?9$\n",
        "[\\.\\?!]\\s*9[…][А-Я][а-яё ,—–-]*:\\n\\s*?[—–-]{1,2}.+?[\\.\\?!]*?9$\n",
        "^9[А-Я][а-яёА-Я ,—–-]*:\\n\\s*?[—–-]{1,2}.+?[\\.\\?!]*?9$\n",
        "[\\.\\?!>]\\s*9[«“\"][А-Я]?[а-яёА-Я ,—–-]*[:;] [«“\"][А-Я][ёа-я ,\\?!\\.…—–-]+[”»\"], [ёа-я ,]+[”»\"]9[\\.\\?!,]*?\n",
        "[\\.\\?!>]\\s*9[«“\"][А-Я]?[а-яёА-Я ,—–-]*[:;] [«“\"][А-Я][ёа-яА-Я ,\\?!\\.…;—–-]+[”»\"] — [ёа-я ,]+[”»\"]9[\\.\\?!,]*?\n",
        "\\s*9\"[А-Я]?[а-яёА-Я ,—–-]*[:;] [«“\"][А-Я][ёа-яА-Я ,\\?!\\.…;—–-]+[”»\"] [ёа-я ,]+\"9[\\.\\?!,]*?\n",
        "[^:][ \\n]9[«“\"][А-Я][а-яёА-Я \\.\\?!—–-]*[”»\"], [а-яёА-Я ]*.(?<!\\w\\.\\w.)(?<![А-Я][а-я]\\.)(?<=\\.|\\?)9\\s\n",
        "[^:][ \\n]9[«“\"][А-Я][а-яА-Яё ,!\\?\\.]*[”»\"], [а-яА-Яё ]*, [«“\"][а-яА-Яё ,!\\?\\.]*[”»\"]9/s\n",
        "[^:][ \\n]9[«“\"][А-Я][А-Яа-яё, !\\?\\.—–-]*[”»\"]9 —–-{1,2}\n",
        "[\\.\\?!]\\s9[А-Я][а-яё ,—–-]*: [«“\"][а-яА-Яё ,—–-]*[”»\"]9\\.\n",
        " — 9[«“\"][а-яёА-Я\\?!\\. ,—–-]*[”»\"]9\\s[^а-яА-Яё]\n",
        " 9[«“\"][а-яА-Яё ,.\\?!—–-]*[”»\"], [—–-] [а-яА-Я ,—–-]*\\.9\\s\n",
        "\\s*9\"[А-Я][А-Яа-яё ,—–-]+[:;] [«“\"][а-яА-Я ;]+[”»\"]\"9[!\\.\\?,]*\n",
        "\\s*9\"[А-Я][-ёа-яА-Я ,;]+: [«“\"][А-Я][-а-я ,]+[”»\"]\"9, [—–-] [<«]\n",
        "\\s*9[«“\"][А-Я][А-Яа-я ё\\?!,]+[”»\"]9 [—–-]{1,2} [«<]\n",
        " [—–-] 9\"[«“\"][А-Я][А-Яа-я ,;-]+[”»\"].\"9\\s\n",
        "\\s9\"[«“\"][А-Я][А-Яа-я ,;!\\?\\.—–-]+[”»\"], [а-яА-Я ]+, «[А-Яа-я ,;!\\?—–-]+[”»\"]\"9 [—–-]{1,2} [«<]'''.splitlines()\n",
        "\n",
        "for line in speech:\n",
        "    \n",
        "    left, s, right = re.split('9', line)\n",
        "    spdict.append([left, s, right])"
      ],
      "metadata": {
        "id": "q0sVZrYzu6Jm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def countdirect(path):\n",
        "    try:\n",
        "        with open(path, encoding='utf-8') as f:\n",
        "            text =  f.read()\n",
        "            \n",
        "    except:\n",
        "        with open(path) as f:\n",
        "            text =  f.read()\n",
        "            \n",
        "    text = re.sub('(\\r\\n)+', '\\n', text)\n",
        "    text = re.sub('\\n+', '\\n', text)\n",
        "\n",
        "    cnting = 0\n",
        "    for nn, el in enumerate(spdict):\n",
        "    \n",
        "        regex = ''.join(el)\n",
        "        found = re.findall(regex, text, flags=re.M)\n",
        "        \n",
        "        \n",
        "        cnting += len(found)\n",
        "        \n",
        "    return cnting"
      ],
      "metadata": {
        "id": "KejaY1U2y75z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Код для выделения причастий"
      ],
      "metadata": {
        "id": "RKXRsWme0uUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def countparticiples(parsed, filename, corp, default=0):\n",
        "    total = 0\n",
        "    meaninsent = []\n",
        "    status = 'participles'\n",
        "    for par in parsed:\n",
        "        insentence = 0\n",
        "        \n",
        "        for n, p in enumerate(par):\n",
        "            if p['deprel'] == 'amod':\n",
        "                if p['lemma'].endswith('ть') or p['lemma'].endswith('ти'):\n",
        "                    total += 1\n",
        "                    insentence += 1\n",
        "                    \n",
        "            if p['deprel'] == 'acl' and p['upos'] == 'VERB':\n",
        "                if p['feats'].get('VerbForm', 0):\n",
        "                    \n",
        "                    if p['feats']['VerbForm'] == 'Part':\n",
        "                        if p['lemma'].endswith('ть') or p['lemma'].endswith('ти'):\n",
        "                            total += 1\n",
        "                            insentence += 1\n",
        "        if insentence:\n",
        "            meaninsent.append(insentence)\n",
        "            \n",
        "    return total, round(total/len(parsed), 4),  round(mean(meaninsent), 4)"
      ],
      "metadata": {
        "id": "VrSMDnss0w0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CUT"
      ],
      "metadata": {
        "id": "y0wOLOkWz3vs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция для подсчета непрямой речи; выделенные объекты показались нерепрезентативными"
      ],
      "metadata": {
        "id": "xKlPx88by8dy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIactbTAuzdh"
      },
      "outputs": [],
      "source": [
        "def countindirect(file):\n",
        "    \n",
        "    with open(file, encoding='utf-8') as f:\n",
        "        conn = f.read()\n",
        "    parsed = parse(conn)\n",
        "    \n",
        "    counting = 0\n",
        "    for par in parsed:\n",
        "        for n, p in enumerate(par):\n",
        "            if p['lemma'] in verblist:\n",
        "                if  p['feats']:\n",
        "                    if p['feats'].get('VerbForm', 0):\n",
        "                        if p['feats']['VerbForm'] != 'Inf':\n",
        "                            if  p['feats'].get('Tense', 0):\n",
        "                                if p['feats']['Tense'] == 'Past':\n",
        "                                    if n + 2<len(par):\n",
        "                                        if par[n+1]['lemma'] == ',' and par[n+2]['lemma'] == 'что' and par[0]['upos'] != 'PUNCT':\n",
        "                                            \n",
        "                                            counting += 1\n",
        "    return counting\n",
        "                        "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подсчитать субъекты транзитивных глаголов и их одушевленность"
      ],
      "metadata": {
        "id": "0enQQAkO05fx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def counttrans(parsed, filename, corp, default=0):\n",
        "    c = defaultdict(int)\n",
        "    status = 'trans'\n",
        "    for par in parsed:\n",
        "        root = None\n",
        "        \n",
        "        \n",
        "        for n, p in enumerate(par):\n",
        "            if p['deprel'] == 'root':\n",
        "                if p['feats']:\n",
        "                    if p['feats'].get('VerbForm', 0):\n",
        "                        if p['feats']['VerbForm'] == 'Fin':\n",
        "                            root = p['id']\n",
        "                    \n",
        "        \n",
        "        if root:\n",
        "            \n",
        "            for n, p in enumerate(par):\n",
        "                \n",
        "                if p['head'] == root and p['deprel'] == 'obj':\n",
        "            \n",
        "            \n",
        "                    for n, p in enumerate(par):\n",
        "                        if p['head'] == root and p['deprel'] == 'nsubj':\n",
        "                            c[p['lemma']] += 1\n",
        "                            \n",
        "                            if p.get('feats',0):\n",
        "                                if p['feats'].get('Animacy', 0):\n",
        "                                    animacy = p['feats']['Animacy']\n",
        "                                else:\n",
        "                                    animacy = p['upos']\n",
        "                            else:\n",
        "                                animacy = p['upos']\n",
        "                                \n",
        "                            if p['lemma'] not in animacydict:\n",
        "                                animacydict[p['lemma']] = animacy\n",
        "                    \n",
        "    \n",
        "    year = metadict[filename]\n",
        "    \n",
        "    \n",
        "    if default == 0:\n",
        "    \n",
        "        with open(f'{corp}_{status}.tsv', 'a+', encoding='utf-8') as f:\n",
        "            for k, v in Counter(c).most_common():\n",
        "                anim = animacydict[k]\n",
        "                f.write(f'{filename}\\t{year}\\t{k}\\t{v}\\t{anim}\\n')\n",
        "                \n",
        "    else:\n",
        "        with open(f'{corp}_{status}_{default}.tsv', 'a+', encoding='utf-8') as f:\n",
        "            for k, v in Counter(c).most_common():\n",
        "                if v > default:\n",
        "                    anim = animacydict[k]\n",
        "                    f.write(f'{filename}\\t{year}\\t{k}\\t{v}\\t{anim}\\n'"
      ],
      "metadata": {
        "id": "Amy9DD4T1BH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Субъекты пассивных предложений, их одушевленность"
      ],
      "metadata": {
        "id": "cWOaqwjs0YiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def countpassives(parsed, filename, corp, default=0):\n",
        "    c = defaultdict(int)\n",
        "    status = 'passives'\n",
        "    for par in parsed:\n",
        "        root = None\n",
        "        \n",
        "        \n",
        "        for n, p in enumerate(par):\n",
        "            if p['deprel'] == 'root':\n",
        "                if p['feats']:\n",
        "                    if p['feats'].get('Voice', 0):\n",
        "                        if p['feats']['Voice'] == 'Pass':\n",
        "                            root = p['id']\n",
        "                \n",
        "        if root:\n",
        "            for n, p in enumerate(par):\n",
        "                if p['head'] == root and 'nsubj'  in p['deprel']:\n",
        "                    c[p['lemma']] += 1\n",
        "                    if p.get('feats',0):\n",
        "                        if p['feats'].get('Animacy', 0):\n",
        "                            animacy = p['feats']['Animacy']\n",
        "                        else:\n",
        "                            animacy = p['upos']\n",
        "                    else:\n",
        "                        animacy = p['upos']\n",
        "                        \n",
        "                    if p['lemma'] not in animacy:\n",
        "                        animacydict[p['lemma']] = animacy\n",
        "                    \n",
        "    \n",
        "    year = metadict[filename]\n",
        "    \n",
        "    \n",
        "    if default == 0:\n",
        "    \n",
        "        with open(f'{corp}_{status}.tsv', 'a+', encoding='utf-8') as f:\n",
        "            for k, v in Counter(c).most_common():\n",
        "                anim = animacydict[k]\n",
        "                f.write(f'{filename}\\t{year}\\t{k}\\t{v}\\t{anim}\\n')\n",
        "                \n",
        "    else:\n",
        "        with open(f'{corp}_{status}_{default}.tsv', 'a+', encoding='utf-8') as f:\n",
        "        \n",
        "            for k, v in Counter(c).most_common():\n",
        "                if v > default:\n",
        "                    anim = animacydict[k]\n",
        "                    f.write(f'{filename}\\t{year}\\t{k}\\t{v}\\t{anim}\\n')\n",
        "        "
      ],
      "metadata": {
        "id": "HnhtRWRF0bnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Предложения без субъекта (по факту находились выражения типа \"Будете чай?\")"
      ],
      "metadata": {
        "id": "LN07sNaq0KOc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def countprodrop(parsed, filename, corp, default=0):\n",
        "    c = defaultdict(int)\n",
        "    status = 'prodrop'\n",
        "    for par in parsed:\n",
        "        root = None\n",
        "        foundsubj = 0\n",
        "        \n",
        "        \n",
        "        for n, p in enumerate(par):\n",
        "            if p['deprel'] == 'root':\n",
        "                if p['feats']:\n",
        "                    if p['feats'].get('VerbForm', 0):\n",
        "                        if p['feats']['VerbForm'] == 'Fin':\n",
        "                            root = p['id']\n",
        "            \n",
        "        for n, p in enumerate(par):\n",
        "                \n",
        "            if p['head'] == root:\n",
        "                if p['deprel'] == 'nsubj' or p['deprel'] == 'nsubj:pass':\n",
        "                    foundsubj = 1\n",
        "                    \n",
        "        if foundsubj == 0:\n",
        "            print(par)\n",
        "        else:\n",
        "            print('XXX')"
      ],
      "metadata": {
        "id": "N5EwuPbz0PzF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}